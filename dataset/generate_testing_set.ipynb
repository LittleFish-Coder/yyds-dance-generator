{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e34acaba",
      "metadata": {},
      "source": [
        "# Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6wVzvIAH_1fE",
      "metadata": {
        "id": "6wVzvIAH_1fE"
      },
      "outputs": [],
      "source": [
        "%pip install -q opencv-python-headless\n",
        "%pip install -q mediapipe\n",
        "%pip install -q numpy\n",
        "%pip install -q rembg"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ea845f6",
      "metadata": {},
      "source": [
        "# Hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "608713fc",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26b9a1b2",
      "metadata": {},
      "outputs": [],
      "source": [
        "video_path = './video/magnetic.mp4'\t# change this to the path of your video\n",
        "output_folder = './test_pose'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b83ec5b",
      "metadata": {},
      "source": [
        "# Create the testing folder"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e22b6bee",
      "metadata": {},
      "source": [
        "- testA: contains the pose skeleton\n",
        "- testB: contains the original frame image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82af40da",
      "metadata": {},
      "outputs": [],
      "source": [
        "# check if the output path exists, if not create it\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "    # make subfolders: testA\n",
        "    os.makedirs(output_folder + '/testA')\n",
        "    os.makedirs(output_folder + '/testB')\n",
        "else:\n",
        "    # remove the directory and recreate\n",
        "    os.system('rm -rf ' + output_folder+'/testA')\n",
        "    os.system('rm -rf ' + output_folder+'/testB')\n",
        "    os.makedirs(output_folder + '/testA')\n",
        "    os.makedirs(output_folder + '/testB')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b93a6f2b",
      "metadata": {},
      "source": [
        "# Prepare MediaPipe for Pose Estimation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5401a007",
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import csv\n",
        "import numpy as np\n",
        "import os\n",
        "import numpy as np\n",
        "from mediapipe import solutions\n",
        "from mediapipe.framework.formats import landmark_pb2\n",
        "from rembg import remove"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7edf562",
      "metadata": {},
      "source": [
        "## Initialize MediaPipe Pose and Drawing utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28c18855",
      "metadata": {},
      "outputs": [],
      "source": [
        "# drawing utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "\n",
        "# partial body pose landmarks\n",
        "mp_pose = mp.solutions.pose\n",
        "pose = mp_pose.Pose(static_image_mode=False, model_complexity=2, enable_segmentation=True, min_detection_confidence=0.1, smooth_landmarks=True)\n",
        "\n",
        "# full body pose landmarks\n",
        "mp_holistic = mp.solutions.holistic\n",
        "holistic = mp_holistic.Holistic(static_image_mode=False, model_complexity=2, enable_segmentation=True, min_detection_confidence=0.1, smooth_landmarks=True)\n",
        "\n",
        "# drawing styles for hands landmarks\n",
        "left_hand_landmark_style = mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=2, circle_radius=2)\n",
        "right_hand_landmark_style = mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01c1da2a",
      "metadata": {},
      "source": [
        "## Inferencing on video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2dc80377",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dc80377",
        "outputId": "ba48dbdf-dda6-4c65-df07-7b8296135671"
      },
      "outputs": [],
      "source": [
        "# Open the video file\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "frame_number = 0\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Convert the frame to RGB\n",
        "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Create a black background image\n",
        "    black_background = np.zeros_like(frame_rgb)\n",
        "\n",
        "    # Process the frame with MediaPipe Pose\n",
        "    result = holistic.process(frame_rgb)\n",
        "\n",
        "    # Draw the pose landmarks on the black background\n",
        "    if result.pose_landmarks:\n",
        "        # Right hand\n",
        "        mp_drawing.draw_landmarks(black_background, result.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, landmark_drawing_spec=right_hand_landmark_style)\n",
        "        # Left hand\n",
        "        mp_drawing.draw_landmarks(black_background, result.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, landmark_drawing_spec=left_hand_landmark_style)\n",
        "        # Body\n",
        "        mp_drawing.draw_landmarks(black_background, result.pose_landmarks, mp_holistic.POSE_CONNECTIONS, landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
        "\n",
        "\n",
        "    # Write out the pose skeleton to testA\n",
        "    cv2.imwrite(f\"{output_folder}/testA/{frame_number}.jpg\", black_background)  # write out the pose skeleton\n",
        "    # Write out the original rgb frame to testB\n",
        "    cv2.imwrite(f\"{output_folder}/testB/{frame_number}.jpg\", frame)  # write out the original frame\n",
        "\n",
        "    # Exit if 'q' key is pressed\n",
        "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "        break\n",
        "\n",
        "    frame_number += 1\n",
        "\n",
        "cap.release()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fea2d362",
      "metadata": {},
      "source": [
        "# Write the pose_dance images to a video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d42b8ea0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# write video out from images in ouput folder\n",
        "\n",
        "images_path = './output'\n",
        "output_path = './output_video'\n",
        "\n",
        "# check if the output path exists, if not create it\n",
        "if not os.path.exists(output_path):\n",
        "    os.makedirs(output_path)\n",
        "\n",
        "image_array = os.listdir(images_path)\n",
        "image_array.sort(key=lambda x: int(x.split('.')[0]))\n",
        "# print(image_array)\n",
        "\n",
        "img_array = []\n",
        "for filename in image_array:\n",
        "    img = cv2.imread(os.path.join(images_path, filename))\n",
        "    height, width, layers = img.shape\n",
        "    size = (width, height)\n",
        "    img_array.append(img)\n",
        "\n",
        "print(f\"Number of frames: {len(img_array)}\")\n",
        "print(f\"Frame size: {size}\")\n",
        "print(img_array)\n",
        "# create the video file\n",
        "# write out as mp4\n",
        "out = cv2.VideoWriter(f'{output_path}/output.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps=30, frameSize=size)\n",
        "# write out as avi\n",
        "# out = cv2.VideoWriter(f'{output_path}/output.avi', cv2.VideoWriter_fourcc(*'DIVX'), 30, size)\n",
        "\n",
        "# write the images to the video file\n",
        "for i in range(len(img_array)):\n",
        "    out.write(img_array[i])\n",
        "\n",
        "out.release()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d5b789a",
      "metadata": {},
      "source": [
        "# Align the pose skeleton with the original frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67dcab9c",
      "metadata": {},
      "outputs": [],
      "source": [
        "!python make_dataset_aligned.py --dataset-path test_pose"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c18cad6c",
      "metadata": {},
      "source": [
        "# Write the aligned images to a video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e66b68d",
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -q moviepy --upgrade\n",
        "%pip install -q Pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d3d9fea",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# write video out from images in ouput folder\n",
        "\n",
        "images_path = './test_pose/test'\n",
        "output_path = './test_pose/'\n",
        "\n",
        "# check if the output path exists, if not create it\n",
        "if not os.path.exists(output_path):\n",
        "    os.makedirs(output_path)\n",
        "\n",
        "image_array = os.listdir(images_path)\n",
        "image_array.sort(key=lambda x: int(x.split('.')[0]))\n",
        "\n",
        "img_array = []\n",
        "for filename in image_array:\n",
        "    img = Image.open(os.path.join(images_path, filename))\n",
        "    img = np.array(img)\n",
        "    height, width, layers = img.shape\n",
        "    size = (width, height)\n",
        "    img_array.append(img)\n",
        "\n",
        "print(f\"Number of frames: {len(img_array)}\")\n",
        "print(f\"Frame size: {size}\")\n",
        "# print(img_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd5f9699",
      "metadata": {},
      "outputs": [],
      "source": [
        "from moviepy.editor import VideoFileClip, AudioFileClip, ImageSequenceClip\n",
        "\n",
        "clip = ImageSequenceClip(img_array, fps=30)  # Adjust fps as needed\n",
        "\n",
        "clip.write_videofile(f'{output_path}/pose2img.mp4', codec='libx264', fps=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7334c3fb",
      "metadata": {},
      "source": [
        "# Combine video and audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9131fd8",
      "metadata": {},
      "outputs": [],
      "source": [
        "from moviepy.editor import VideoFileClip, AudioFileClip\n",
        "\n",
        "output_video_path = \"./video/magnetic_pose2img.mp4\"\n",
        "input_video_path = \"./test_pose/pose2img.mp4\"\n",
        "input_audio_path = \"./video/magnetic.mp4\"\n",
        "\n",
        "# Create a video clip\n",
        "video = VideoFileClip(f\"{input_video_path}\")\n",
        "\n",
        "# Create an audio clip\n",
        "audio = AudioFileClip(f\"{input_audio_path}\")\n",
        "\n",
        "# get the duration\n",
        "print(f\"Video duration: {video.duration}\")\n",
        "print(f\"Audio duration: {audio.duration}\")\n",
        "\n",
        "# duration = min(video.duration, audio.duration)\n",
        "\n",
        "# set the duration\n",
        "# video = video.set_duration(duration)\n",
        "# audio = audio.set_duration(duration)\n",
        "\n",
        "# # Add the audio clip to the video clip\n",
        "video = video.set_audio(audio)\n",
        "\n",
        "# Write the result to a file\n",
        "video.write_videofile(f\"{output_video_path}\", codec=\"libx264\", audio_codec=\"aac\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
