{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e34acaba",
      "metadata": {},
      "source": [
        "# Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6wVzvIAH_1fE",
      "metadata": {
        "id": "6wVzvIAH_1fE"
      },
      "outputs": [],
      "source": [
        "%pip install -q opencv-python-headless\n",
        "%pip install -q mediapipe\n",
        "%pip install -q numpy\n",
        "%pip install -q rembg"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ea845f6",
      "metadata": {},
      "source": [
        "# Hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "608713fc",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26b9a1b2",
      "metadata": {},
      "outputs": [],
      "source": [
        "video_path = './video/fish.mov'\t# change this to the path of your video\n",
        "output_folder = './training_pose2img'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b83ec5b",
      "metadata": {},
      "source": [
        "# Create the training folder"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e22b6bee",
      "metadata": {},
      "source": [
        "- train: contains the pose skeleton and image side by side\n",
        "- trainA: contains the pose skeleton\n",
        "- trainB: contains the original image but without background"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82af40da",
      "metadata": {},
      "outputs": [],
      "source": [
        "# check if the output path exists, if not create it\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "    # make subfolders: train, trainA, trainB\n",
        "    os.makedirs(output_folder + '/train')\n",
        "    os.makedirs(output_folder + '/trainA')\n",
        "    os.makedirs(output_folder + '/trainB')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b93a6f2b",
      "metadata": {},
      "source": [
        "# Prepare MediaPipe for Pose Estimation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5401a007",
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import csv\n",
        "import numpy as np\n",
        "import os\n",
        "import numpy as np\n",
        "from mediapipe import solutions\n",
        "from mediapipe.framework.formats import landmark_pb2\n",
        "from rembg import remove"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7edf562",
      "metadata": {},
      "source": [
        "## Initialize MediaPipe Pose and Drawing utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28c18855",
      "metadata": {},
      "outputs": [],
      "source": [
        "# drawing utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "\n",
        "# partial body pose landmarks\n",
        "mp_pose = mp.solutions.pose\n",
        "pose = mp_pose.Pose(static_image_mode=False, model_complexity=2, enable_segmentation=True, min_detection_confidence=0.1, smooth_landmarks=True)\n",
        "\n",
        "# full body pose landmarks\n",
        "mp_holistic = mp.solutions.holistic\n",
        "holistic = mp_holistic.Holistic(static_image_mode=False, model_complexity=2, enable_segmentation=True, min_detection_confidence=0.1, smooth_landmarks=True)\n",
        "\n",
        "# drawing styles for hands landmarks\n",
        "left_hand_landmark_style = mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=2, circle_radius=2)\n",
        "right_hand_landmark_style = mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01c1da2a",
      "metadata": {},
      "source": [
        "## Inferencing on video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2dc80377",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dc80377",
        "outputId": "ba48dbdf-dda6-4c65-df07-7b8296135671"
      },
      "outputs": [],
      "source": [
        "# Open the video file\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "frame_number = 0\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Convert the frame to RGB\n",
        "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Create a black background image\n",
        "    black_background = np.zeros_like(frame_rgb)\n",
        "\n",
        "    # Process the frame with MediaPipe Pose\n",
        "    result = holistic.process(frame_rgb)\n",
        "\n",
        "    # Draw the pose landmarks on the black background\n",
        "    if result.pose_landmarks:\n",
        "        # Right hand\n",
        "        mp_drawing.draw_landmarks(black_background, result.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, landmark_drawing_spec=right_hand_landmark_style)\n",
        "        # Left hand\n",
        "        mp_drawing.draw_landmarks(black_background, result.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, landmark_drawing_spec=left_hand_landmark_style)\n",
        "        # Body\n",
        "        mp_drawing.draw_landmarks(black_background, result.pose_landmarks, mp_holistic.POSE_CONNECTIONS, landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
        "    \n",
        "    # remove background\n",
        "    removed_background = remove(frame_rgb)  # output shape: (height, width, RGBA)\n",
        "    removed_background = cv2.cvtColor(removed_background, cv2.COLOR_BGR2RGB)    # convert to RGB\n",
        "    \n",
        "    # write out the images\n",
        "    cv2.imwrite(f\"{output_folder}/trainA/{frame_number}.jpg\", black_background)  # write out the pose skeleton\n",
        "    cv2.imwrite(f\"{output_folder}/trainB/{frame_number}.jpg\", removed_background)  # write out the image without background\n",
        "\n",
        "    # Exit if 'q' key is pressed\n",
        "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "        break\n",
        "\n",
        "    frame_number += 1\n",
        "\n",
        "cap.release()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd17c47d",
      "metadata": {},
      "source": [
        "# Align the pose skeleton with the extractd image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0528f6e",
      "metadata": {},
      "outputs": [],
      "source": [
        "from align_dataset import align_images\n",
        "\n",
        "align_images(source_folder=f\"{output_folder}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fea2d362",
      "metadata": {},
      "source": [
        "# Write the aligned images to a video (optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "433a9f6a",
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -q moviepy --upgrade\n",
        "%pip install -q Pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d42b8ea0",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# write video out from images\n",
        "images_path = './training_pose2img/train'\n",
        "output_path = './training_pose2img/'\n",
        "\n",
        "# check if the output path exists, if not create it\n",
        "if not os.path.exists(output_path):\n",
        "    os.makedirs(output_path)\n",
        "\n",
        "image_array = os.listdir(images_path)\n",
        "image_array.sort(key=lambda x: int(x.split('.')[0]))\n",
        "\n",
        "img_array = []\n",
        "for filename in image_array:\n",
        "    img = Image.open(os.path.join(images_path, filename))\n",
        "    img = np.array(img)\n",
        "    height, width, layers = img.shape\n",
        "    size = (width, height)\n",
        "    img_array.append(img)\n",
        "\n",
        "print(f\"Number of frames: {len(img_array)}\")\n",
        "print(f\"Frame size: {size}\")\n",
        "# print(img_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "388f9ff0",
      "metadata": {},
      "outputs": [],
      "source": [
        "from moviepy.editor import VideoFileClip, AudioFileClip, ImageSequenceClip\n",
        "\n",
        "clip = ImageSequenceClip(img_array, fps=30)  # Adjust fps as needed\n",
        "\n",
        "clip.write_videofile(f'{output_path}/pose2img.mp4', codec='libx264', audio_codec=\"aac\", fps=30)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
