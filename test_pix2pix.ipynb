{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wNjDKdQy35h"
      },
      "source": [
        "# Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRm-USlsHgEV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# check if `pytorch-CycleGAN-and-pix2pix` is already cloned\n",
        "if not os.path.exists('pytorch-CycleGAN-and-pix2pix'):\n",
        "\t!git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pt3igws3eiVp"
      },
      "outputs": [],
      "source": [
        "os.chdir('pytorch-CycleGAN-and-pix2pix/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1EySlOXwwoa"
      },
      "outputs": [],
      "source": [
        "%pip install -q -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UkcaFZiyASl"
      },
      "source": [
        "# Testing\n",
        "\n",
        "test the model with single mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mey7o6j-0368"
      },
      "outputs": [],
      "source": [
        "!ls checkpoints/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCsKkEq0yGh0"
      },
      "outputs": [],
      "source": [
        "! python test.py --dataroot ./datasets/test_pose/testA --name fish_pix2pix --model test --netG unet_256 --direction AtoB --dataset_mode single --norm batch --num_test 10000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Combine all the generated images into a video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "images_path = 'results/fish_pix2pix/test_latest/images/'\n",
        "output_path = 'results/fish_pix2pix/videos/'\n",
        "output_width, output_height = 1280, 720\n",
        "\n",
        "# check if the output path exists, if not create it\n",
        "if not os.path.exists(output_path):\n",
        "    os.makedirs(output_path)\n",
        "\n",
        "image_array = os.listdir(images_path)\n",
        "# only keep the images that with 'fake_B' in the name\n",
        "image_array = [x for x in image_array if '_fake' in x]\n",
        "image_array.sort(key=lambda x: int(x.split('_')[0]))\n",
        "# print(image_array)\n",
        "\n",
        "img_array = []\n",
        "for filename in image_array:\n",
        "    img = Image.open(f'{images_path}/{filename}')\n",
        "    # resize the image\n",
        "    img = img.resize((output_width, output_height), resample=Image.BICUBIC)\n",
        "    img = np.array(img)\n",
        "    img_array.append(img)\n",
        "\n",
        "print(f\"Number of frames: {len(img_array)}\")\n",
        "print(f\"Frame size: {(output_width, output_height)}\")\n",
        "# print(img_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from moviepy.editor import VideoFileClip, AudioFileClip, ImageSequenceClip\n",
        "\n",
        "clip = ImageSequenceClip(img_array, fps=30)  # Adjust fps as needed\n",
        "\n",
        "# set audio\n",
        "audio = AudioFileClip('../src/magnetic.mp4')\n",
        "\n",
        "clip = clip.set_audio(audio)\n",
        "\n",
        "clip.write_videofile(f'../src/magnetic_fish.mp4', codec='libx264', audio_codec=\"aac\", fps=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Combine the video\n",
        "\n",
        "combine 3 imgs into a video\n",
        "- real_world_dance\n",
        "- real_world_pose\n",
        "- generated_video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_img_folder = 'datasets/test_pose/dance2pose/'\n",
        "gen_img_array = img_array\n",
        "\n",
        "# sort the test images\n",
        "test_img_array = os.listdir(test_img_folder)\n",
        "test_img_array.sort(key=lambda x: int(x.split('.')[0]))\n",
        "\n",
        "print(f\"Number of test images: {len(test_img_array)}\")\n",
        "print(f\"Number of generated images: {len(gen_img_array)}\")\n",
        "\n",
        "# combine the test and generated images\n",
        "combined_img_array = []\n",
        "for test_img, gen_img in zip(test_img_array, gen_img_array):\n",
        "    test_img = Image.open(f'{test_img_folder}/{test_img}')\n",
        "    gen_img = Image.fromarray(gen_img)\n",
        "    combined_img = Image.new('RGB', (3*output_width, output_height))\n",
        "    combined_img.paste(test_img, (0, 0))\n",
        "    combined_img.paste(gen_img, (2*output_width, 0))\n",
        "    combined_img = np.array(combined_img)\n",
        "    combined_img_array.append(combined_img)\n",
        "    \n",
        "print(f\"Number of combined images: {len(combined_img_array)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Write the video out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from moviepy.editor import ImageSequenceClip\n",
        "\n",
        "clip = ImageSequenceClip(combined_img_array, fps=30)  # Adjust fps as needed\n",
        "\n",
        "audio_clip = AudioFileClip(\"../src/magnetic.mp4\")\n",
        "\n",
        "clip = clip.set_audio(audio_clip)\n",
        "\n",
        "clip.write_videofile(f'../src/magnetic_dance2pose2fish.mp4', codec='libx264', audio_codec=\"aac\",  fps=30)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "pix2pix",
      "provenance": []
    },
    "environment": {
      "name": "tf2-gpu.2-3.m74",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m74"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
