{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6wVzvIAH_1fE",
      "metadata": {
        "id": "6wVzvIAH_1fE"
      },
      "outputs": [],
      "source": [
        "%pip install -q opencv-python-headless\n",
        "%pip install -q mediapipe\n",
        "%pip install -q numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66d2718a",
      "metadata": {},
      "outputs": [],
      "source": [
        "from mediapipe import solutions\n",
        "from mediapipe.framework.formats import landmark_pb2\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def draw_landmarks_on_image(rgb_image, detection_result):\n",
        "  pose_landmarks_list = detection_result.pose_landmarks\n",
        "  annotated_image = np.copy(rgb_image)\n",
        "\n",
        "  # Loop through the detected poses to visualize.\n",
        "  for idx in range(len(pose_landmarks_list)):\n",
        "    pose_landmarks = pose_landmarks_list[idx]\n",
        "\n",
        "    # Draw the pose landmarks.\n",
        "    pose_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
        "    pose_landmarks_proto.landmark.extend([\n",
        "      landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in pose_landmarks\n",
        "    ])\n",
        "    solutions.drawing_utils.draw_landmarks(\n",
        "      annotated_image,\n",
        "      pose_landmarks_proto,\n",
        "      solutions.pose.POSE_CONNECTIONS,\n",
        "      solutions.drawing_styles.get_default_pose_landmarks_style())\n",
        "  return annotated_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2dc80377",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dc80377",
        "outputId": "ba48dbdf-dda6-4c65-df07-7b8296135671"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import csv\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def write_landmarks_to_csv(landmarks, frame_number, csv_data):\n",
        "    print(f\"Landmark coordinates for frame {frame_number}:\")\n",
        "    for idx, landmark in enumerate(landmarks):\n",
        "        print(f\"{mp_pose.PoseLandmark(idx).name}: (x: {landmark.x}, y: {landmark.y}, z: {landmark.z})\")\n",
        "        csv_data.append([frame_number, mp_pose.PoseLandmark(idx).name, landmark.x, landmark.y, landmark.z])\n",
        "    print(\"\\n\")\n",
        "\n",
        "video_path = './src/magnetic.mp4'\n",
        "output_path = './test'\n",
        "output_csv = './outputOfClip.csv'\n",
        "write_out_csv = False\n",
        "\n",
        "# check if the output path exists, if not create it\n",
        "\n",
        "if not os.path.exists(output_path):\n",
        "    os.makedirs(output_path)\n",
        "    \n",
        "\n",
        "# Initialize MediaPipe Pose and Drawing utilities\n",
        "mp_pose = mp.solutions.pose\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "pose = mp_pose.Pose()\n",
        "\n",
        "# Open the video file\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "frame_number = 0\n",
        "csv_data = []\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Convert the frame to RGB\n",
        "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "\t# resize the frame as 256x256\n",
        "    # frame_rgb = cv2.resize(frame_rgb, (256, 256))\n",
        "\n",
        "    # Create a black background image\n",
        "    black_background = np.zeros_like(frame_rgb)\n",
        "\n",
        "    # Process the frame with MediaPipe Pose\n",
        "    result = pose.process(frame_rgb)\n",
        "\n",
        "    # Draw the pose landmarks on the black background\n",
        "    if result.pose_landmarks:\n",
        "        # mp_drawing.draw_landmarks(black_background, result.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
        "        # black_background = draw_landmarks_on_image(black_background, result)\n",
        "        mp_drawing.draw_landmarks(\n",
        "            black_background,\n",
        "            result.pose_landmarks,\n",
        "            mp_pose.POSE_CONNECTIONS,\n",
        "            landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
        "\n",
        "        # Add the landmark coordinates to the list and print them\n",
        "        write_landmarks_to_csv(result.pose_landmarks.landmark, frame_number, csv_data)\n",
        "\n",
        "    # Concatenate the original frame and black background containing pose landmarks\n",
        "    combined_frame = np.concatenate((black_background, frame_rgb), axis=1)\n",
        "    combined_frame = cv2.cvtColor(combined_frame, cv2.COLOR_BGR2RGB)    # convert back to BGR for displaying\n",
        "\n",
        "    # Display the combined frame\n",
        "    # cv2.imshow('MediaPipe Pose', combined_frame)  # not work for Linux\n",
        "\n",
        "\n",
        "    # Write out the combined frame\n",
        "    cv2.imwrite(f'{output_path}/{frame_number}.jpg', combined_frame)  # write out the combined frame\n",
        "    # cv2.imwrite(f'{output_path}/{frame_number}.jpg', black_background)  # write out the background pose frame\n",
        "\n",
        "\n",
        "    # Exit if 'q' key is pressed\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "    frame_number += 1\n",
        "\n",
        "cap.release()\n",
        "\n",
        "if write_out_csv:\n",
        "    # Save the CSV data to a file\n",
        "    with open(output_csv, 'w', newline='') as csvfile:\n",
        "        csv_writer = csv.writer(csvfile)\n",
        "        csv_writer.writerow(['frame_number', 'landmark', 'x', 'y', 'z'])\n",
        "        csv_writer.writerows(csv_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fea2d362",
      "metadata": {},
      "source": [
        "# Write the pose_dance images to a video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d42b8ea0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# write video out from images in ouput folder\n",
        "\n",
        "images_path = './output'\n",
        "output_path = './output_video'\n",
        "\n",
        "# check if the output path exists, if not create it\n",
        "if not os.path.exists(output_path):\n",
        "    os.makedirs(output_path)\n",
        "\n",
        "image_array = os.listdir(images_path)\n",
        "image_array.sort(key=lambda x: int(x.split('.')[0]))\n",
        "# print(image_array)\n",
        "\n",
        "img_array = []\n",
        "for filename in image_array:\n",
        "    img = cv2.imread(os.path.join(images_path, filename))\n",
        "    height, width, layers = img.shape\n",
        "    size = (width, height)\n",
        "    img_array.append(img)\n",
        "\n",
        "print(f\"Number of frames: {len(img_array)}\")\n",
        "print(f\"Frame size: {size}\")\n",
        "print(img_array)\n",
        "# create the video file\n",
        "# write out as mp4\n",
        "out = cv2.VideoWriter(f'{output_path}/output.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps=30, frameSize=size)\n",
        "\n",
        "# write the images to the video file\n",
        "for i in range(len(img_array)):\n",
        "    out.write(img_array[i])\n",
        "\n",
        "out.release()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7334c3fb",
      "metadata": {},
      "source": [
        "# Combine video and audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c347fad6",
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -q moviepy --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9131fd8",
      "metadata": {},
      "outputs": [],
      "source": [
        "from moviepy.editor import VideoFileClip, AudioFileClip\n",
        "\n",
        "output_name = 'magnetic.mp4'\n",
        "output_path = \"./output_video_audio\"\n",
        "video_path = \"./output_video/magnetic.mp4\"\n",
        "audio_path = \"./src/magnetic.mp4\"\n",
        "\n",
        "# Create a video clip\n",
        "video = VideoFileClip(f\"{video_path}\")\n",
        "\n",
        "# Create an audio clip\n",
        "audio = AudioFileClip(f\"{audio_path}\")\n",
        "\n",
        "# get the duration\n",
        "print(f\"Video duration: {video.duration}\")\n",
        "print(f\"Audio duration: {audio.duration}\")\n",
        "\n",
        "duration = min(video.duration, audio.duration)\n",
        "\n",
        "# set the duration\n",
        "# video = video.set_duration(duration)\n",
        "# audio = audio.set_duration(duration)\n",
        "\n",
        "# # Add the audio clip to the video clip\n",
        "video = video.set_audio(audio)\n",
        "\n",
        "# Write the result to a file\n",
        "video.write_videofile(f\"{output_path}/{output_name}\", codec=\"libx264\", audio_codec=\"aac\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cadd1016",
      "metadata": {},
      "source": [
        "# Combine Source Video and Generated Video Together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b5b3995",
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from moviepy.editor import VideoFileClip, AudioFileClip\n",
        "\n",
        "source_video = \"./src/magnetic.mp4\"\n",
        "generated_video = \"./output_video_audio/magnetic.mp4\"\n",
        "\n",
        "\n",
        "# Open the video files\n",
        "cap1 = cv2.VideoCapture(source_video)\n",
        "cap2 = cv2.VideoCapture(generated_video)\n",
        "\n",
        "# Check if the videos are opened successfully\n",
        "if not cap1.isOpened() or not cap2.isOpened():\n",
        "    print('Could not open videos')\n",
        "    exit()\n",
        "\n",
        "# Create a VideoWriter object\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "fps = 30\n",
        "frame_size = (640*2, 480)  # double width to accommodate two videos\n",
        "out = cv2.VideoWriter('combined.mp4', fourcc, fps, frame_size)\n",
        "\n",
        "\n",
        "while True:\n",
        "    # Read frames from the videos\n",
        "    ret1, frame1 = cap1.read()\n",
        "    ret2, frame2 = cap2.read()\n",
        "\n",
        "    # If either video ends, break the loop\n",
        "    if not ret1 or not ret2:\n",
        "        break\n",
        "\n",
        "    # Resize the frames if necessary\n",
        "    frame1 = cv2.resize(frame1, (640, 480))\n",
        "    frame2 = cv2.resize(frame2, (640, 480))\n",
        "\n",
        "    # Concatenate the frames horizontally\n",
        "    combined = np.concatenate((frame1, frame2), axis=1)\n",
        "    \n",
        "\t# write out the combined frame\n",
        "    out.write(combined)\n",
        "\n",
        "    # Display the combined frame\n",
        "    # cv2.imshow('Combined', combined)\n",
        "\n",
        "    # Break the loop if 'q' is pressed\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release the video files and close all windows\n",
        "cap1.release()\n",
        "cap2.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51c1bb87",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert the video to mp4 by using moviepy\n",
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "video_path = 'combine/combined.mp4'\n",
        "audio_path = 'src/magnetic.mp4'\n",
        "output_path = 'combine/result.mp4'\n",
        "\n",
        "# Create a video clip\n",
        "video = VideoFileClip(f\"{video_path}\")\n",
        "\n",
        "# Create an audio clip\n",
        "audio = AudioFileClip(f\"{audio_path}\")\n",
        "\n",
        "# Add the audio clip to the video clip\n",
        "video = video.set_audio(audio)\n",
        "\n",
        "video.write_videofile(output_path, codec=\"libx264\", audio_codec=\"aac\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
